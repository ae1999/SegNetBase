{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "processed-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm.contrib import tzip\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "documentary-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "historic-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNetBase(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels = 3, out_channels = 32, debug = False):\n",
    "        \n",
    "        super(SegNetBase, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        ## encode:\n",
    "        \n",
    "        self.encoder_0 = nn.Sequential(*[nn.Conv2d(in_channels = self.in_channels, out_channels = 64,\n",
    "                                            kernel_size=7, padding=3), nn.BatchNorm2d(64)])\n",
    "        self.encoder_1 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = 64,\n",
    "                                            kernel_size=7, padding=3), nn.BatchNorm2d(64)])\n",
    "        self.encoder_2 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = 64,\n",
    "                                            kernel_size=7, padding=3), nn.BatchNorm2d(64)])\n",
    "        self.encoder_3 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = 64,\n",
    "                                            kernel_size=7, padding=3), nn.BatchNorm2d(64)])\n",
    "        \n",
    "        ## decode:\n",
    "        \n",
    "        self.decoder_3 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = 64,\n",
    "                                            kernel_size = 7, padding = 3), nn.BatchNorm2d(64)])\n",
    "        self.decoder_2 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = 64,\n",
    "                                            kernel_size=7, padding=3), nn.BatchNorm2d(64)])\n",
    "        self.decoder_1 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = 64,\n",
    "                                            kernel_size=7, padding=3), nn.BatchNorm2d(64)])\n",
    "        self.decoder_0 = nn.Sequential(*[nn.Conv2d(in_channels = 64, out_channels = self.out_channels,\n",
    "                                            kernel_size=1, padding=0)])\n",
    "    def forward(self, x):\n",
    "\n",
    "        debug = self.debug\n",
    "\n",
    "        ## encode:\n",
    "        x_0_size = x.size()\n",
    "        x = self.encoder_0(x)\n",
    "        x = F.relu(x)\n",
    "        x_e0_size = x.size()\n",
    "        x, indices_0 = F.max_pool2d(x, kernel_size = 2, stride = 2, return_indices = True)\n",
    "        \n",
    "        x_1_size = x.size()\n",
    "        x = self.encoder_1(x)\n",
    "        x = F.relu(x)\n",
    "        x_e1_size = x.size()\n",
    "        x, indices_1 = F.max_pool2d(x, kernel_size = 2, stride = 2, return_indices = True)\n",
    "        \n",
    "        x_2_size = x.size()\n",
    "        x = self.encoder_2(x)\n",
    "        x = F.relu(x)\n",
    "        x_e2_size = x.size()\n",
    "        x, indices_2 = F.max_pool2d(x, kernel_size = 2, stride = 2, return_indices = True)\n",
    "        \n",
    "        x_3_size = x.size()\n",
    "        x = self.encoder_3(x)\n",
    "        x = F.relu(x)\n",
    "        x_e3_size = x.size()\n",
    "        x, indices_3 = F.max_pool2d(x, kernel_size = 2, stride = 2, return_indices = True)\n",
    "        \n",
    "        ## decode:\n",
    "        encoded_size = x.size()\n",
    "\n",
    "        x = F.max_unpool2d(x, indices_3, kernel_size = 2, stride = 2, output_size = x_3_size)\n",
    "        x = self.decoder_3(x)\n",
    "        x = F.relu(x)\n",
    "        x_d3_size = x.size()\n",
    "        \n",
    "        x = F.max_unpool2d(x, indices_2, kernel_size = 2, stride = 2, output_size = x_2_size)\n",
    "        x = self.decoder_2(x)\n",
    "        x = F.relu(x)\n",
    "        x_d2_size = x.size()\n",
    "        \n",
    "        x = F.max_unpool2d(x, indices_1, kernel_size = 2, stride = 2, output_size = x_1_size)\n",
    "        x = self.decoder_1(x)\n",
    "        x = F.relu(x)\n",
    "        x_d1_size = x.size()\n",
    "        \n",
    "        x = F.max_unpool2d(x, indices_0, kernel_size = 2, stride = 2, output_size = x_0_size)\n",
    "        x = self.decoder_0(x)\n",
    "        x = F.relu(x)\n",
    "        x_d0_size = x.size()\n",
    "        \n",
    "        x_softmax = F.softmax(x, dim=1)\n",
    "\n",
    "        if debug:\n",
    "            print(\"x_0_size: {}\".format(x_0_size))\n",
    "            print(\"x_1_size: {}\".format(x_1_size))\n",
    "            print(\"x_2_size: {}\".format(x_2_size))\n",
    "            #print(\"x_3_size: {}\".format(x_3_size))\n",
    "\n",
    "            print(\"encoded_size: {}\".format(encoded_size))\n",
    "\n",
    "            #print(\"x_d3_size: {}\".format(x_d3_size))\n",
    "            print(\"x_d2_size: {}\".format(x_d2_size))\n",
    "            print(\"x_d1_size: {}\".format(x_d1_size))\n",
    "            print(\"x_d0_size: {}\".format(x_d0_size))\n",
    "\n",
    "        return x, x_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "introductory-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, NUM_EPOCHS = 30, log = True, load = False):\n",
    "    \n",
    "    print('Epochs:\\t', NUM_EPOCHS)\n",
    "    if load:\n",
    "        model = SegNetBase()\n",
    "        model.load_state_dict(torch.load(\"./model_best.pth\"))\n",
    "    \n",
    "    losses = []\n",
    "    t_losses = []\n",
    "    prev_loss = float('inf')\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loss_f = []\n",
    "        t_start = time.time()\n",
    "\n",
    "        for i, (input_tensor, target_tensor) in enumerate(train_loader):\n",
    "            \n",
    "            input_tensor = torch.autograd.Variable(input_tensor)\n",
    "            target_tensor = torch.autograd.Variable(target_tensor)\n",
    "            \n",
    "            predicted_tensor, softmaxed_tensor = model(input_tensor) #print(target_tensor.shape, predicted_tensor.shape)\n",
    "            target_tensor = target_tensor.type(torch.LongTensor)\n",
    "            loss = criterion(predicted_tensor, target_tensor)\n",
    "            \n",
    "            if log: print('batch loss:', float(loss))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_f.append(float(loss))\n",
    "            prediction_f = softmaxed_tensor.float()\n",
    "        \n",
    "        delta = time.time() - t_start\n",
    "        \n",
    "        dataiter = iter(test_loader)\n",
    "        images, label = dataiter.next()\n",
    "        input_tensor = torch.autograd.Variable(images)\n",
    "        target_tensor = torch.autograd.Variable(label)\n",
    "        predicted_tensor, softmaxed_tensor = model(input_tensor)\n",
    "        target_tensor = target_tensor.type(torch.LongTensor)\n",
    "        test_loss = criterion(predicted_tensor, target_tensor)\n",
    "        \n",
    "        if np.array(loss_f).mean() < prev_loss:\n",
    "            prev_loss = np.array(loss_f).mean()\n",
    "            torch.save(model.state_dict(), './model_best.pth')\n",
    "        \n",
    "        losses.append(np.array(loss_f).mean())\n",
    "        t_losses.append(float(test_loss))\n",
    "        \n",
    "        print(\"Epoch #{}\\ttrain loss: {:.8f}\\ttest loss: {:.8f}\\t Time: {:2f}s\".format(epoch+1, np.array(loss_f).mean(),t_losses[-1], delta))\n",
    "        \n",
    "    return losses, t_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "twenty-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(test_loader, model = None, model_path = ''):\n",
    "    dr = Data_reader()\n",
    "    correctnesses = []\n",
    "    model = SegNetBase()\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    if len(model_path):\n",
    "        model = SegNetBase()\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    model.eval()\n",
    "    images = []\n",
    "    labels = []\n",
    "    results = []\n",
    "    \n",
    "    i = 0\n",
    "    for img, label in test_loader:\n",
    "        if i > 10:\n",
    "            break\n",
    "        i += 1\n",
    "        img = img.to(device)\n",
    "        label = label.cpu().numpy()\n",
    "        label = label.squeeze()\n",
    "        output, class_prob = model(img)\n",
    "        a = 1 - torch.count_nonzero((torch.argmax(class_prob, axis = 1)-torch.tensor(label)))/(360*480)\n",
    "        model_output = dr.rev_translate(torch.argmax(class_prob, axis = 1))\n",
    "        \n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "        results.append(model_output)\n",
    "        correctnesses.append(a)\n",
    "    return images, labels, results, correctnesses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_x86",
   "language": "python",
   "name": "pytorch_x86"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
